{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from revuresnet18 import revuresnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3d():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.model.conv1 = nn.Conv2d(4, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Linear(512, 200) #encode_dim =200 (latent vec dim)\n",
    "        self.encoder = nn.Sequential(self.model)\n",
    "        \n",
    "        n_dims=200; \n",
    "        nf=512;\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "\n",
    "        nn.ConvTranspose3d(n_dims, nf, 4, stride=1, padding=0, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf, nf//2, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//2, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//2, nf//4, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//4, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//4, nf//8, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//8, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//8, nf//16, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//16, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(nf//16, 1, 4, stride=2, padding=1, dilation=1, groups=1, bias=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        latent_vec = self.encoder(x.float())\n",
    "        latent_vec = latent_vec.view(latent_vec.size(0), -1, 1, 1, 1)\n",
    "        vox = self.decoder(latent_vec)\n",
    "        \n",
    "        return latent_vec, vox;\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: torch.Size([1, 3, 480, 480])\n",
      "Depth: torch.Size([1, 1, 480, 480])\n",
      "Silhouette: torch.Size([1, 1, 480, 480])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "depth = cv2.imread(\"depth.png\")\n",
    "normal = cv2.imread(\"normal.png\")\n",
    "sil = cv2.imread(\"sil.png\")\n",
    "\n",
    "\n",
    "\n",
    "normal = normal.transpose(2,0,1).reshape(-1,3,480,480)\n",
    "depth = depth.transpose(2,0,1)\n",
    "depth = depth[0,:,:].reshape(-1,1,480,480)\n",
    "sil = sil.transpose(2,0,1)\n",
    "sil = sil[0,:,:].reshape(-1,1,480,480)\n",
    "\n",
    "normal = torch.from_numpy(normal)\n",
    "depth = torch.from_numpy(depth)\n",
    "sil = torch.from_numpy(sil)\n",
    "\n",
    "\n",
    "print(\"Normal:\", normal.shape)\n",
    "print(\"Depth:\", depth.shape)\n",
    "print(\"Silhouette:\", sil.shape)\n",
    "\n",
    "\n",
    "is_bg = sil <= 0 #self.silhou_thres\n",
    "depth[is_bg] = 0\n",
    "normal[is_bg.repeat(1, 3, 1, 1)] = 0 # NOTE: if old net2, set to white (100),\n",
    "x = torch.cat((depth, normal), 1) # and swap depth and normal\n",
    "\n",
    "model = Model3d()\n",
    "L, V = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 1, 1, 1])\n",
      "torch.Size([1, 1, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(L.shape)\n",
    "print(V.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shapehd",
   "language": "python",
   "name": "shapehd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
