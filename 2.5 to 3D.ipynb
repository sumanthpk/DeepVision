{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from revuresnet18 import revuresnet18\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(index, batch_size):\n",
    "    superpath = \"/home/ghostvortex/Documents/DL_Project/Dataset/\"\n",
    "    voxel = []\n",
    "    normal_img = []\n",
    "    depth_img = []\n",
    "    sil_img = []\n",
    "    for folder in sorted(os.listdir(superpath))[index+1:(index+int(batch_size/20)+1)]:\n",
    "        for folder_in in sorted(os.listdir(superpath+folder)):\n",
    "            for files in sorted(os.listdir(superpath+folder+\"/\"+folder_in)):\n",
    "                #print(count, \" \",superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                if \"rotvox\" in files:\n",
    "                    img = np.load(superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    label = np.where(labels['voxel']>0.5,1,0)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img).unsqueeze(0)\n",
    "                    voxel.append(img)\n",
    "                    \n",
    "                elif \"depth\" in files:\n",
    "                    img = cv2.imread(superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    depth_img.append(img)\n",
    "                elif \"normal\" in files:\n",
    "                    img = cv2.imread(superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img).unsqueeze(0)\n",
    "                    normal_img.append(img)\n",
    "                elif \"sil\" in files:\n",
    "                    img = cv2.imread(superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    sil_img.append(img)\n",
    "                    \n",
    "    voxel1 = torch.cat(voxel, dim=0)\n",
    "    normal_img1 = torch.cat(normal_img, dim=0)\n",
    "    depth_img1 = torch.cat(depth_img, dim=0)\n",
    "    sil_img1 = torch.cat(sil_img, dim=0)\n",
    "    \n",
    "    is_bg = sil_img1 <= 0 #self.silhou_thres\n",
    "    depth_img1[is_bg] = 0\n",
    "    normal_img1[is_bg.repeat(1, 3, 1, 1)] = 0 # NOTE: if old net2, set to white (100),\n",
    "    x = torch.cat((depth_img1, normal_img1), 1) # and swap depth and normal             \n",
    "\n",
    "    return voxel1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Model3d, self).__init__()\n",
    "        self.model = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.model.conv1 = nn.Conv2d(4, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Linear(512, 200) #encode_dim =200 (latent vec dim)\n",
    "        self.encoder = nn.Sequential(self.model)\n",
    "        \n",
    "        n_dims=200; \n",
    "        nf=512;\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "        nn.ConvTranspose3d(n_dims, nf, 4, stride=1, padding=0, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf, nf//2, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//2, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//2, nf//4, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//4, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//4, nf//8, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//8, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//8, nf//16, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//16, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(nf//16, 1, 4, stride=2, padding=1, dilation=1, groups=1, bias=True)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        latent_vec = self.encoder(x.float())\n",
    "        latent_vec = latent_vec.view(latent_vec.size(0), -1, 1, 1, 1)\n",
    "        vox = self.decoder(latent_vec)\n",
    "        \n",
    "        return vox;\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  0.8094754219055176\n",
      "Epoch:  10 Loss:  0.16951245069503784\n",
      "Epoch:  20 Loss:  0.1525782346725464\n",
      "Epoch:  30 Loss:  0.14245781302452087\n",
      "Epoch:  40 Loss:  0.13064508140087128\n",
      "Epoch:  50 Loss:  0.1194363683462143\n",
      "Epoch:  60 Loss:  0.11170250922441483\n",
      "Epoch:  70 Loss:  0.10146713256835938\n",
      "Epoch:  80 Loss:  0.08196892589330673\n",
      "Epoch:  90 Loss:  0.07366722077131271\n",
      "Epoch:  100 Loss:  0.06507912278175354\n",
      "Epoch:  110 Loss:  0.053190600126981735\n",
      "Epoch:  120 Loss:  0.04480641335248947\n",
      "Epoch:  130 Loss:  0.036886066198349\n",
      "Epoch:  140 Loss:  0.031138595193624496\n",
      "Epoch:  150 Loss:  0.026902638375759125\n",
      "Epoch:  160 Loss:  0.023647820577025414\n",
      "Epoch:  170 Loss:  0.021144459024071693\n",
      "Epoch:  180 Loss:  0.019044533371925354\n",
      "Epoch:  190 Loss:  0.017489340156316757\n",
      "Epoch:  200 Loss:  0.015617168508470058\n",
      "Epoch:  210 Loss:  0.014504157938063145\n",
      "Epoch:  220 Loss:  0.013246258720755577\n",
      "Epoch:  230 Loss:  0.012325410731136799\n",
      "Epoch:  240 Loss:  0.011560434475541115\n",
      "Epoch:  250 Loss:  0.010480673983693123\n",
      "Epoch:  260 Loss:  0.009770464152097702\n",
      "Epoch:  270 Loss:  0.009686275385320187\n",
      "Epoch:  280 Loss:  0.008640135638415813\n",
      "Epoch:  290 Loss:  0.008006485179066658\n",
      "Epoch:  300 Loss:  0.007498390041291714\n",
      "Epoch:  310 Loss:  0.007219153456389904\n",
      "Epoch:  320 Loss:  0.006748497486114502\n",
      "Epoch:  330 Loss:  0.006319710519164801\n",
      "Epoch:  340 Loss:  0.0059927101247012615\n",
      "Epoch:  350 Loss:  0.005693101789802313\n",
      "Epoch:  360 Loss:  0.006162494886666536\n",
      "Epoch:  370 Loss:  0.006042199209332466\n",
      "Epoch:  380 Loss:  0.005333760753273964\n",
      "Epoch:  390 Loss:  0.004949261900037527\n",
      "Epoch:  400 Loss:  0.004706378560513258\n",
      "Epoch:  410 Loss:  0.004495998844504356\n",
      "Epoch:  420 Loss:  0.004314033314585686\n",
      "Epoch:  430 Loss:  0.004150191321969032\n",
      "Epoch:  440 Loss:  0.004007301293313503\n",
      "Epoch:  450 Loss:  0.003865958657115698\n",
      "Epoch:  460 Loss:  0.0043567512184381485\n",
      "Epoch:  470 Loss:  0.004079783335328102\n",
      "Epoch:  480 Loss:  0.0036089629866182804\n",
      "Epoch:  490 Loss:  0.0034480576869100332\n"
     ]
    }
   ],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def train(self, model):\n",
    "        \n",
    "        num_epochs = 500\n",
    "        num_batch  = 1\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(reduction = 'elementwise_mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        \n",
    "        if torch.cuda.device_count() >= 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model.to(device)\n",
    "        \n",
    "        f = open('/home/ghostvortex/models/status-second-module.txt','w').close()\n",
    "\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            ind = 0\n",
    "            \n",
    "            for i in range(int(2150/(batch_size/20))):\n",
    "                \n",
    "                print(\"Epoch:\", epoch,\", Iteration:\",i)\n",
    "                # Load data and labels of that batch\n",
    "                f = open('/home/ghostvortex/models/status-first-module.txt','a')\n",
    "                f.write(\"Epoch:  \" + str(epoch) + \",  Iteration:\" + str(i)+ \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                voxel, x = loader(ind, batch_size)\n",
    "                \n",
    "                \n",
    "                out = voxel.to(device)\n",
    "                inp = x.to(device)\n",
    "                \n",
    "                try:\n",
    "                    output = model.forward(inp)\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if 'out of memory' in str(e):\n",
    "                        sys.stdout.flush()\n",
    "                        for p in model.parameters():\n",
    "                            if p.grad is not None:\n",
    "                                del p.grad\n",
    "                        torch.cuda.empty_cache()\n",
    "                        output = model.forward(inp)\n",
    "                    else: raise e\n",
    "\n",
    "                loss = criterion(output,label.type(torch.FloatTensor))      \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                ind += batch_size // 20\n",
    "            \n",
    "            print(\"Epoch: \", epoch , \"Loss: \", loss.item())\n",
    "            f = open('/home/ghostvortex/models/status-first-module.txt','a')\n",
    "            f.write(\"\\n\"+\"Epoch:  \" + str(epoch) + \",  Loss:\" + str(loss.item())+ \"\\n\")\n",
    "            f.close()\n",
    "        f.close()\n",
    "        return model\n",
    "                \n",
    "\n",
    "model = Model3d()\n",
    "trainer = Trainer(model)\n",
    "trained_model = trainer.train(model)\n",
    "torch.save(trained_model.state_dict(),'/home/ghostvortex/models/second_module.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "#V = trained_model.forward(x)\n",
    "#V = V.detach().numpy().squeeze()\n",
    "#temp = np.where(V < 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# z,x,y = temp.nonzero()\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(x, y, -z, zdir='z', c = 'red')\n",
    "# #ax.view_init(azim=-45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "# from skimage import measure\n",
    "# from skimage.draw import ellipsoid\n",
    "# verts, faces, normals, values = measure.marching_cubes_lewiner(temp, 0)\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "# mesh111 = Poly3DCollection(verts[faces])\n",
    "# mesh111.set_edgecolor('k')\n",
    "# ax.add_collection3d(mesh111)\n",
    "\n",
    "# ax.set_xlim(0, 128) \n",
    "# ax.set_ylim(0, 128)  \n",
    "# ax.set_zlim(0, 128)  \n",
    "# #ax.view_init(azim=-45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# print(verts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
