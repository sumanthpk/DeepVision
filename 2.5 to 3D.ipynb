{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:12:18.562756Z",
     "start_time": "2019-11-26T04:12:18.548009Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from revuresnet18 import revuresnet18\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:12:19.644654Z",
     "start_time": "2019-11-26T04:12:19.378786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:13:54.847567Z",
     "start_time": "2019-11-26T04:13:54.817524Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model3d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Model3d, self).__init__()\n",
    "        self.model = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.model.conv1 = nn.Conv2d(4, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Linear(512, 200) #encode_dim =200 (latent vec dim)\n",
    "        self.encoder = nn.Sequential(self.model)\n",
    "        \n",
    "        n_dims=200; \n",
    "        nf=512;\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "        nn.ConvTranspose3d(n_dims, nf, 4, stride=1, padding=0, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf, nf//2, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//2, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//2, nf//4, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//4, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//4, nf//8, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//8, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//8, nf//16, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//16, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(nf//16, 1, 4, stride=2, padding=1, dilation=1, groups=1, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        latent_vec = self.encoder(x.float())\n",
    "        latent_vec = latent_vec.view(latent_vec.size(0), -1, 1, 1, 1)\n",
    "        vox = self.decoder(latent_vec)\n",
    "        return vox;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:20:41.158826Z",
     "start_time": "2019-11-26T04:20:41.131237Z"
    }
   },
   "outputs": [],
   "source": [
    "def loader(index, batch_size):\n",
    "    superpath_rgb = \"/home/ghostvortex/Documents/DL_Project/Dataset/\"\n",
    "    superpath_3d = \"/home/ghostvortex/Documents/DL_Project/3D/\"\n",
    "    voxel = []\n",
    "    normal_img = []\n",
    "    depth_img = []\n",
    "    sil_img = []\n",
    "    \n",
    "    for folder in sorted(os.listdir(superpath_3d))[index+1:(index+int(batch_size/20)+1)]:\n",
    "        for folder_in in sorted(os.listdir(superpath_3d+folder)):\n",
    "            for files in sorted(os.listdir(superpath_3d+folder+\"/\"+folder_in)):\n",
    "                #print(count, \" \",superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                if \"rotvox\" in files:\n",
    "                    labels = np.load(superpath_3d+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    label = np.where(labels['voxel']>0.5,1,0)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    label = transform(label).unsqueeze(0)\n",
    "                    voxel.append(label)\n",
    "    \n",
    "    for folder in sorted(os.listdir(superpath_rgb))[index+1:(index+int(batch_size/20)+1)]:\n",
    "        for folder_in in sorted(os.listdir(superpath_rgb+folder)):\n",
    "            for files in sorted(os.listdir(superpath_rgb+folder+\"/\"+folder_in)):\n",
    "                #print(count, \" \",superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                if \"depth\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    depth_img.append(img)\n",
    "                elif \"normal\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img).unsqueeze(0)\n",
    "                    normal_img.append(img)\n",
    "                elif \"sil\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    sil_img.append(img)\n",
    "                    \n",
    "    voxel1 = torch.cat(voxel, dim=0)\n",
    "    normal_img1 = torch.cat(normal_img, dim=0)\n",
    "    depth_img1 = torch.cat(depth_img, dim=0)\n",
    "    sil_img1 = torch.cat(sil_img, dim=0)\n",
    "    \n",
    "    is_bg = sil_img1 <= 0 #self.silhou_thres\n",
    "    depth_img1[is_bg] = 0\n",
    "    normal_img1[is_bg.repeat(1, 3, 1, 1)] = 0 # NOTE: if old net2, set to white (100),\n",
    "    x = torch.cat((depth_img1, normal_img1), 1) # and swap depth and normal             \n",
    "\n",
    "    return voxel1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:23:30.378147Z",
     "start_time": "2019-11-26T04:22:03.130321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , Iteration: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 503316480 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c01b75fc6e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/home/ghostvortex/models/second_module.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c01b75fc6e9d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c01b75fc6e9d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-c882d1ad8320>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlatent_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlatent_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mvox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvox\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    919\u001b[0m         return F.conv_transpose3d(\n\u001b[1;32m    920\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 503316480 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def train(self, model):\n",
    "        num_epochs = 500\n",
    "        batch_size = 60\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(reduction = 'elementwise_mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        \n",
    "        if torch.cuda.device_count() >= 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model.to(device)\n",
    "        \n",
    "        f = open('/home/ghostvortex/models/status-second-module.txt','w').close()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            ind = 0\n",
    "            for i in range(int(2150/(batch_size/20))):\n",
    "                print(\"Epoch:\", epoch,\", Iteration:\",i)\n",
    "                # Load data and labels of that batch\n",
    "                f = open('/home/ghostvortex/models/status-first-module.txt','a')\n",
    "                f.write(\"Epoch:  \" + str(epoch) + \",  Iteration:\" + str(i)+ \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                voxel, x = loader(ind, batch_size)\n",
    "                label = voxel.to(device)\n",
    "                inp = x.to(device)\n",
    "                \n",
    "                try:\n",
    "                    output = model.forward(inp)\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if 'out of memory' in str(e):\n",
    "                        sys.stdout.flush()\n",
    "                        for p in model.parameters():\n",
    "                            if p.grad is not None:\n",
    "                                del p.grad\n",
    "                        torch.cuda.empty_cache()\n",
    "                        output = model.forward(inp)\n",
    "                    else: raise e\n",
    "\n",
    "                loss = criterion(output,label.type(torch.FloatTensor))      \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                ind += batch_size // 20\n",
    "            print(\"Epoch: \", epoch , \"Loss: \", loss.item())\n",
    "            f = open('/home/ghostvortex/models/status-first-module.txt','a')\n",
    "            f.write(\"\\n\"+\"Epoch:  \" + str(epoch) + \",  Loss:\" + str(loss.item())+ \"\\n\")\n",
    "            f.close()\n",
    "        f.close()\n",
    "        return model\n",
    "\n",
    "model = Model3d()\n",
    "trainer = Trainer(model)\n",
    "trained_model = trainer.train(model)\n",
    "torch.save(trained_model.state_dict(),'/home/ghostvortex/models/second_module.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "#V = trained_model.forward(x)\n",
    "#V = V.detach().numpy().squeeze()\n",
    "#temp = np.where(V < 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# z,x,y = temp.nonzero()\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(x, y, -z, zdir='z', c = 'red')\n",
    "# #ax.view_init(azim=-45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "# from skimage import measure\n",
    "# from skimage.draw import ellipsoid\n",
    "# verts, faces, normals, values = measure.marching_cubes_lewiner(temp, 0)\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "# mesh111 = Poly3DCollection(verts[faces])\n",
    "# mesh111.set_edgecolor('k')\n",
    "# ax.add_collection3d(mesh111)\n",
    "\n",
    "# ax.set_xlim(0, 128) \n",
    "# ax.set_ylim(0, 128)  \n",
    "# ax.set_zlim(0, 128)  \n",
    "# #ax.view_init(azim=-45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# print(verts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
