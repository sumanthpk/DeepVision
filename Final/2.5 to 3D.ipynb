{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T07:59:12.163776Z",
     "start_time": "2019-12-03T07:59:11.564909Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from revuresnet18 import revuresnet18\n",
    "from skimage import measure\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for empty folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for objects in sorted(os.listdir('/home/ghostvortex/Dataset/Dataset/')):\n",
    "    count = 0\n",
    "    for objects_ in sorted(os.listdir('/home/ghostvortex/Dataset/Dataset/'+objects+'/')):\n",
    "        count+=1\n",
    "    if count < 20: print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T07:59:16.447240Z",
     "start_time": "2019-12-03T07:59:16.424225Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model3d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Model3d, self).__init__()\n",
    "        self.model = models.resnet18(pretrained = True)\n",
    "        \n",
    "        self.model.conv1 = nn.Conv2d(4, 64, 7, stride=2, padding=3, bias=False)\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Linear(512, 200) #encode_dim =200 (latent vec dim)\n",
    "        self.encoder = nn.Sequential(self.model)\n",
    "        \n",
    "        n_dims=200; \n",
    "        nf=512;\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "        nn.ConvTranspose3d(n_dims, nf, 4, stride=1, padding=0, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf, nf//2, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//2, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//2, nf//4, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//4, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//4, nf//8, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//8, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(nf//8, nf//16, 4, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "        nn.BatchNorm3d(nf//16, eps=1e-5, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose3d(nf//16, 1, 4, stride=2, padding=1, dilation=1, groups=1, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        latent_vec = self.encoder(x.float())\n",
    "        latent_vec = latent_vec.view(latent_vec.size(0), -1, 1, 1, 1)\n",
    "        vox = self.decoder(latent_vec)\n",
    "        return vox;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:20:41.158826Z",
     "start_time": "2019-11-26T04:20:41.131237Z"
    }
   },
   "outputs": [],
   "source": [
    "def loader(index, batch_size):\n",
    "    superpath_rgb = \"/home/ghostvortex/Dataset/Dataset/\"\n",
    "    superpath_3d = \"/home/ghostvortex/3D/\"\n",
    "    voxel = []\n",
    "    normal_img = []\n",
    "    depth_img = []\n",
    "    sil_img = []\n",
    "    \n",
    "    for folder in sorted(os.listdir(superpath_3d))[index+1:(index+int(batch_size/20)+1)]:\n",
    "        for folder_in in sorted(os.listdir(superpath_3d+folder)):\n",
    "            for files in sorted(os.listdir(superpath_3d+folder+\"/\"+folder_in)):\n",
    "                # print(count, \" \",superpath+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                if \"rotvox\" in files:\n",
    "                    labels = np.load(superpath_3d+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    label = np.where(labels['voxel']>0.5,1,0)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    label = transform(label).unsqueeze(0)\n",
    "                    voxel.append(label)\n",
    "    \n",
    "    for folder in sorted(os.listdir(superpath_rgb))[index+1:(index+int(batch_size/20)+1)]:\n",
    "        for folder_in in sorted(os.listdir(superpath_rgb+folder)):\n",
    "            for files in sorted(os.listdir(superpath_rgb+folder+\"/\"+folder_in)):\n",
    "                # print(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                if \"depth\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    depth_img.append(img)\n",
    "                elif \"normal\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img).unsqueeze(0)\n",
    "                    normal_img.append(img)\n",
    "                elif \"sil\" in files:\n",
    "                    img = cv2.imread(superpath_rgb+folder+\"/\"+folder_in+\"/\"+files)\n",
    "                    transform = torchvision.transforms.ToTensor()\n",
    "                    img = transform(img[:,:,0]).unsqueeze(0)\n",
    "                    sil_img.append(img)\n",
    "                    \n",
    "    voxel1 = torch.cat(voxel, dim=0)\n",
    "    normal_img1 = torch.cat(normal_img, dim=0)\n",
    "    depth_img1 = torch.cat(depth_img, dim=0)\n",
    "    sil_img1 = torch.cat(sil_img, dim=0)\n",
    "    \n",
    "    is_bg = sil_img1 <= 0 #self.silhou_thres\n",
    "    depth_img1[is_bg] = 0\n",
    "    normal_img1[is_bg.repeat(1, 3, 1, 1)] = 0 # NOTE: if old net2, set to white (100),\n",
    "    x = torch.cat((depth_img1, normal_img1), 1) # and swap depth and normal             \n",
    "    return voxel1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T07:59:18.220668Z",
     "start_time": "2019-12-03T07:59:18.205618Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_obj_str(verts, faces):\n",
    "    text = \"\"\n",
    "    for p in verts:\n",
    "        text += \"v \"\n",
    "        for x in p:\n",
    "            text += \"{} \".format(x)\n",
    "        text += \"\\n\"\n",
    "    for f in faces:\n",
    "        text += \"f \"\n",
    "        for x in f:\n",
    "            text += \"{} \".format(x + 1)\n",
    "        text += \"\\n\"\n",
    "    return text\n",
    "\n",
    "def save_iso_obj(df, path, th, shift=True):\n",
    "    if th < np.min(df):\n",
    "        df[0, 0, 0] = th - 1\n",
    "    if th > np.max(df):\n",
    "        df[-1, -1, -1] = th + 1\n",
    "    spacing = (1 / 128, 1 / 128, 1 / 128)\n",
    "    verts, faces, _, _ = measure.marching_cubes_lewiner(\n",
    "        df, th, spacing=spacing)\n",
    "    if shift:\n",
    "        verts -= np.array([0.5, 0.5, 0.5])\n",
    "    obj_str = to_obj_str(verts, faces)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(obj_str)\n",
    "\n",
    "def vis_voxel(voxels, path, counter=0, th=0.25, use_sigmoid=True):\n",
    "    m = nn.Sigmoid()\n",
    "    voxels = m(voxels)\n",
    "    voxels = voxels.detach().numpy().squeeze()\n",
    "    save_iso_obj(voxels, path, th=th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T04:23:30.378147Z",
     "start_time": "2019-11-26T04:22:03.130321Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def train(self, model):\n",
    "        num_epochs = 15\n",
    "        batch_size = 20\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(reduction = 'elementwise_mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        \n",
    "        if torch.cuda.device_count() >= 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model.to(device)\n",
    "        \n",
    "        f = open('/home/ghostvortex/models/status-second-module.txt','w').close()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            ind = 0\n",
    "            for i in range(int(300/(batch_size/20))):\n",
    "                print(\"Epoch:\", epoch,\", Iteration:\",i)\n",
    "                # Load data and labels of that batch\n",
    "                f = open('/home/ghostvortex/models/status-second-module.txt','a')\n",
    "                f.write(\"Epoch:  \" + str(epoch) + \",  Iteration:\" + str(i)+ \"\\n\")\n",
    "                f.close()\n",
    "                \n",
    "                voxel, x = loader(ind, batch_size)\n",
    "                label = voxel.to(device)\n",
    "                inp = x.to(device)\n",
    "                \n",
    "                try:\n",
    "                    output = model.forward(inp)\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if 'out of memory' in str(e):\n",
    "                        sys.stdout.flush()\n",
    "                        for p in model.parameters():\n",
    "                            if p.grad is not None:\n",
    "                                del p.grad\n",
    "                        torch.cuda.empty_cache()\n",
    "                        output = model.forward(inp)\n",
    "                    else: raise e\n",
    "\n",
    "                output = output.squeeze()\n",
    "                loss = criterion(output.type(torch.FloatTensor),label.type(torch.FloatTensor)) \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                ind += batch_size // 20\n",
    "            print(\"Epoch: \", epoch , \"Loss: \", loss.item())\n",
    "            f = open('/home/ghostvortex/models/status-second-module.txt','a')\n",
    "            f.write(\"\\n\"+\"Epoch:  \" + str(epoch) + \",  Loss:\" + str(loss.item())+ \"\\n\")\n",
    "            f.close()\n",
    "        f.close()\n",
    "        return model\n",
    "    \n",
    "def init_func(m, init_type= 'kaiming'):\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "        if init_type == 'kaiming':\n",
    "            torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.init.normal_(m.weight.data, 1.0, init_param)\n",
    "        torch.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "model = Model3d()\n",
    "model.apply(init_func)\n",
    "model = model.cuda()\n",
    "trainer = Trainer(model)\n",
    "trained_model = trainer.train(model)\n",
    "torch.save(trained_model.state_dict(),'/home/ghostvortex/models/second_module.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T07:59:22.909064Z",
     "start_time": "2019-12-03T07:59:22.437030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = Model3d()\n",
    "weights.load_state_dict(torch.load('models/second_module.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T09:09:23.673483Z",
     "start_time": "2019-12-03T09:09:22.156298Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count = 20\n",
    "normal_img1 = cv2.imread('2p5d_results/normal_sample.jpg')\n",
    "# normal_img1 = cv2.imread('/home/ghostvortex/Documents/DL_Project/DeepVision/Final/temp_pix/'+str(count)+'/normal'+str(count)+'.png')\n",
    "normal_img1 = cv2.resize(normal_img1, (256,256))\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "normal_img1 = transform(normal_img1).unsqueeze(0)\n",
    "depth_img1 = cv2.imread('2p5d_results/depth_sample.jpg')\n",
    "# depth_img1 = cv2.imread('/home/ghostvortex/Documents/DL_Project/DeepVision/Final/temp_pix/'+str(count)+'/depth'+str(count)+'.png')\n",
    "depth_img1 = cv2.resize(depth_img1, (256,256))\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "depth_img1 = transform(depth_img1[:,:,0]).unsqueeze(0)\n",
    "sil_img1 = cv2.imread('2p5d_results/sil_sample.jpg')\n",
    "# sil_img1 = cv2.imread('/home/ghostvortex/Documents/DL_Project/DeepVision/Final/temp_pix/'+str(count)+'/silhouette'+str(count)+'.png')\n",
    "sil_img1 = cv2.resize(sil_img1, (256,256))\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "sil_img1 = transform(sil_img1[:,:,0]).unsqueeze(0)\n",
    "is_bg = sil_img1 <= 0 #self.silhou_thres\n",
    "depth_img1[is_bg] = 0\n",
    "normal_img1[is_bg.repeat(1, 3, 1, 1)] = 0 # NOTE: if old net2, set to white (100),\n",
    "x = torch.cat((depth_img1, normal_img1), 1) # and swap depth and normal     \n",
    "V = weights(x)\n",
    "# vis_voxel(V,'3D_models/3D_fake'+str(count)+'.obj')\n",
    "vis_voxel(V, '3D_models/3D_param.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T01:10:42.309022Z",
     "start_time": "2019-12-03T01:10:42.285666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "temp = np.where(V<-1, 0, 1).squeeze()\n",
    "print(temp.squeeze().shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "z,x,y = temp.nonzero()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, -z, zdir='z', c = 'red')\n",
    "ax.view_init(azim=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from skimage import measure\n",
    "from skimage.draw import ellipsoid\n",
    "verts, faces, normals, values = measure.marching_cubes_lewiner(temp, 0)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "mesh111 = Poly3DCollection(verts[faces])\n",
    "mesh111.set_edgecolor('k')\n",
    "ax.add_collection3d(mesh111)\n",
    "\n",
    "ax.set_xlim(0, 128) \n",
    "ax.set_ylim(0, 128)  \n",
    "ax.set_zlim(0, 128)  \n",
    "#ax.view_init(azim=-45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(verts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
